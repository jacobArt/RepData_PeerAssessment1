quiz <- read.csv("getdata-data-ss06hid.csv")
head(quiz)
library(dplyr)
filter(quiz, ADJUST >= 1000000)
summarize(quiz, total(ADJUST >= 1000000))
?summarize
summarize(quiz, length(which(ADJUST >= 1000000)))
millions <- filter(quiz, ADJUST >= 1000000)
length(millions
)
?nrow
nrow(millions)
?rmv
View(millions)
View(millions)
millions <- filter(quiz, VAL == 24)
nrow(millions)
quiz1 <- read.csv("getdata-data-DATA.gov_NGAP.csv")
quiz1 <- read.xlsx("getdata-data-DATA.gov_NGAP.xlsx")
library(xlsx)
help("install")
help("INSTALL")
install.packages("xlsx")
library(xlsx)
library(rJava)
quiz1 <- read.xlsx("getdata-data-DATA.gov_NGAP.xlsx")
library(xlsx)
if(!require(installr)) {
install.packages("installr"); require(installr)}
library(xlsx)
library(rJava)
library(xlsx)
quiz1 <- read.xlsx("getdata-data-DATA.gov_NGAP.xlsx")
?read.xlsx
quiz1 <- read.xlsx("getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1)
?nrow
library(dplyr)
nrow(quiz1, 18:23)
library(xlsx)
quiz1 <- read.xlsx("getdata-data-DATA.gov_NGAP.xlsx", sheetIndex = 1)
dat <- quiz1[c(18:23), c(7:15)]
sum(dat$Zip*dat$Ext,na.rm=T)
dat
sum(quiz1$Zip*quiz1$Ext,na.rm=T)
install.packages(data.table)
data.table()
library(data.table)
install.packages("data.table")
library(data.table)
fread("getdata-data-ss06pid.csv")
quiz2 <- read.csv("getdata-data-ss06pid.csv")
system.time(fread(quiz2))
system.time(fread("getdata-data-ss06pid.csv"))
DT = quiz2
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
1 <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
first <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
second <- mean(DT$pwgtp15,by=DT$SEX)
first
second
third <- sapply(split(DT$pwgtp15,DT$SEX),mean)
four <- DT[,mean(pwgtp15),by=SEX]
fifth <- rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
sixth <- tapply(DT$pwgtp15,DT$SEX,mean)
system.time(fread(first))
file <- tempfile()
write.table(quiz2, file=file, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)
system.time(fread(first))
?Devices
rm(list=ls())
#reading data into R:
cons<- read.table("household_power_consumption.txt", sep=";",nrows= 2075260, header=TRUE, quote= "", strip.white=TRUE, stringsAsFactors = FALSE, na.strings= "?")
# Subsetting the full data to obtain the data related to two days:
sub<- subset(cons, (cons$Date == "1/2/2007" | cons$Date== "2/2/2007"))
# Changing the class of Date variable from character to Date:
sub$Date <- as.Date(sub$Date, format = "%d/%m/%Y")
# Creating the plot3:
png("plot1.png", width = 480, height = 480)
hist(sub$Global_active_power, type="l", main="Global Active Power",col='red',ylab= "Frequency", xlab="Global Active Power(kilowatts)")
dev.off()
rm(list=ls())
#reading data into R:
cons<- read.table("household_power_consumption.txt", sep=";",nrows= 2075260, header=TRUE, quote= "", strip.white=TRUE, stringsAsFactors = FALSE, na.strings= "?")
# Subsetting the full data to obtain the data related to two days:
sub<- subset(cons, (cons$Date == "1/2/2007" | cons$Date== "2/2/2007"))
# Changing the class of Date variable from character to Date:
sub$Date <- as.Date(sub$Date, format = "%d/%m/%Y")
# Combining the Date and Time variable and creating a new column in dataset named "DateTime":
sub$DateTime <- as.POSIXct(paste(sub$Date, sub$Time))
# Creating the plot2:
png("plot2.png", width = 480, height = 480)
plot(sub$DateTime, sub$Global_active_power, type="l", ylab= "Global Active Power(kilowatts)", xlab="")
dev.off()
rm(list=ls())
#reading data into R:
cons<- read.table("household_power_consumption.txt", sep=";",nrows= 2075260, header=TRUE, quote= "", strip.white=TRUE, stringsAsFactors = FALSE, na.strings= "?")
# Subsetting the full data to obtain the data related to two days:
sub<- subset(cons, (cons$Date == "1/2/2007" | cons$Date== "2/2/2007"))
# Changing the class of Date variable from character to Date:
sub$Date <- as.Date(sub$Date, format = "%d/%m/%Y")
# Combining the Date and Time variable and creating a new column in dataset named "DateTime":
sub$DateTime <- as.POSIXct(paste(sub$Date, sub$Time))
# Creating the plot3:
png("plot3.png", width = 480, height = 480)
plot(sub$DateTime, sub$Sub_metering_1, type="l", ylab= "Energy sub metering", xlab="")
lines(sub$DateTime, sub$Sub_metering_2, type="l", col="red")
lines(sub$DateTime, sub$Sub_metering_3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, col=c("black", "red", "blue"))
dev.off()
rm(list=ls())
#reading data into R:
cons<- read.table("household_power_consumption.txt", sep=";",nrows= 2075260, header=TRUE, quote= "", strip.white=TRUE, stringsAsFactors = FALSE, na.strings= "?")
# Subsetting the full data to obtain the data related to two days:
sub<- subset(cons, (cons$Date == "1/2/2007" | cons$Date== "2/2/2007"))
# Changing the class of Date variable from character to Date:
sub$Date <- as.Date(sub$Date, format = "%d/%m/%Y")
# Combining the Date and Time variable and creating a new column in dataset named "DateTime":
sub$DateTime <- as.POSIXct(paste(sub$Date, sub$Time))
# Creating the plot4:
png("plot4.png", width = 480, height = 480)
par(mfcol=c(2,2))
plot(sub$DateTime, sub$Global_active_power, type="l", ylab= "Global Active Power", xlab="")
plot(sub$DateTime, sub$Sub_metering_1, type="l", ylab= "Energy sub metering", xlab="")
lines(sub$DateTime, sub$Sub_metering_2, type="l", col="red")
lines(sub$DateTime, sub$Sub_metering_3, type="l", col="blue")
legend("topright", c("Sub_metering_1", "Sub_metering_2", "Sub_metering_3"), lty=1, col=c("black", "red", "blue"))
plot(sub$DateTime,sub$Voltage,type="l",ylab="Voltage",xlab="datetime")
plot(sub$DateTime,sub$Global_reactive_power,type='l',xlab="datetime",ylab="Global_reactive_power")
dev.off()
swirl()
library(swirl)
swirl()
head(1)
head(pollution)
dim(pollution)
summary(pollution$pm25)
ppm
quantile(ppm)
swirl()
library(swirl)
swirl()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
head(BodyWeight)
table(BodyWeight$Diet)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(httr)
require(httpuv)
require(jsonlite)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications
#    Insert your values below - if secret is omitted, it will look it up in
#    the GITHUB_CONSUMER_SECRET environmental variable.
#
#    Use http://localhost:1410 as the callback url
myapp <- oauth_app("quiz2", "ddb0d599de51ccd02f4b", secret="6af1109f6ecf442d292425087d49bb13d9bbe9c8")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
install.packages(httpuv)
installed.packages()
library(httr)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. To make your own application, register at at
#    https://github.com/settings/applications. Use any URL for the homepage URL
#    (http://github.com is fine) and  http://localhost:1410 as the callback url
#
#    Replace your key and secret below.
myapp <- oauth_app("github",
key = "56b637a5baffac62cad9",
secret = "8e107541ae1791259e9987d544ca568633da2ebf")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
> library(httr)
> oauth_endpoints("github")
> myapp ", secret = "")
> github_token  req  stop_for_status(req)
> content(req)
> BROWSE("https://api.github.com/users/jtleek/repos",authenticate("Access Token","x-oauth-basic","basic"))
> fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
> download.file(fileUrl, destfile="./pid.csv")
> library(sqldf)
> acs <- read.csv("./pid.csv", header=T, sep=",")
> sqldf("select pwgtp1 from acs where AGEP < 50")
getwd()
> fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
> download.file(fileUrl, destfile="./pid.csv")
> library(sqldf)
> acs <- read.csv("./pid.csv", header=T, sep=",")
> sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
install.packages(sqldf)
install.packages(“RMySQL”, type = “source”)
install.packages("rmysql")
install.packages("“RMySQL”")
install.packages(“RMySQL”, type = “source”)
library(RMySQL)
library(RMySQL)
con <- dbConnect(MySQL(), host="127.0.0.1", port= 3306, user="user",
password = "password", dbname="db")
ucscDB <- dbConnect(MySWL(),user="genome",
host="genome-myswl.cse.ucsc.edu")
ucscDB <- dbConnect(MySWL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
ucscDB <- dbConnect(MySQL(),user="genome",
host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(ucscDB,"show databases;"); dbDisconnect(ucscDB)
result
hg19 <- dbConnect(MySQL(),user="genome", db="hg19",
host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
length(allTables)
allTables(1:5)
allTables[1:5]
dbDisconnect(hg19)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
> download.file(fileUrl, destfile="./pid.csv")
> library(sqldf)
> acs <- read.csv("./pid.csv", header=T, sep=",")
> sqldf("select pwgtp1 from acs where AGEP < 50")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./pid.csv")
library(sqldf)
acs <- read.csv("./pid.csv", header=T, sep=",")
sqldf("select pwgtp1 from acs where AGEP < 50")
install.packages(sqldf)
library(swirl)
swirl()
library(dplyr)
cran <- tlb_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran)
by_package <- group_by(cran, package)
by_package
summarize(mean)
j
apple
by_package
summarize(by_package, mean(size))
pack_sum <- summarize(by_package,
count = ,
unique = ,
countries = ,
avg_bytes = )
by_package
reset()
reset()
k
by_package
(reset())
submit()
count = n()
pack_sum <- summarize(by_package, count = , unique = , countries = , avg_bytes = )
pack_sum <- summarize(by_package,
count = ,
unique = ,
countries = ,
avg_bytes = )
pack_sum <- summarize(by_package,
count = n(),
unique = n_distinct(ip_id),
countries = n_distinct(country),
avg_bytes = mean(size))
submit(pack_sum)
submit()
submit(pack_sum)
submit("summarize1.R")
submit(summarize1.R)
submit()
tbl(pack_sum)
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum)
filter(pack_sum, count > 679)
top_counts <- filter(pack_sum, count > 679)
top_counts
view(top_counts)
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
top_unique
View(top_unique)
top_unique_sorter <- arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran
submit()
submit()
submit()
submit()
?mutate
submit
submit()
reset()
script_vals_identical()
submit()
submit()
submit()
submit()
# Getting and Cleaning Data
# Coursera
# John Hopkins University
# Bastiaan Quast
# bquast@gmail.com
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
file.dest <- 'ACS.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# read the data
ACS <- read.csv('ACS.csv')
# create vector
ACS$agricultureLogical <- ifelse(ACS$ACR==3 & ACS$AGS==6,TRUE,FALSE)
# read lines
which(ACS$agricultureLogical)
library(sqldf)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "acs.csv", method = "curl")
dateDownloaded <- date()
acs <- read.table("./acs.csv",sep=",",header=TRUE)
head(acs)
# households on greater than 10 acres who sold more than $10,000 worth of agriculture products
# ACR=3 AND AGS=6
agricultureLogical<-(acs$ACR==3 & acs$AGS==6)
which(agricultureLogical)
class(agricultureLogical)
install.packages("jpeg")
library(jpeg)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "jeff.jpg", method = "curl")
img.n<-readJPEG("jeff.jpg",TRUE)
quantile(img.n,probs=c(0.3,0.8))
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "gdp.csv", method = "curl")
gdp <- read.csv("./gdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "edu.csv", method = "curl")
edu <- read.csv("./edu.csv")
X=CountryCode
names(gdp)
names(edu)
head(gdp)
head(edu)
gdpclean<-gdp[5:194,]
mergedData=as.data.frame(merge(gdpclean,edu,by.x="X",by.y="CountryCode"))
mergedData$Gross.domestic.product.2012 = as.numeric(as.character(mergedData$Gross.domestic.product.2012))
summary(mergedData[mergedData$Income.Group=="High income: OECD",])
quantile(mergedData$Gross.domestic.product.2012,probs=c(0.2,0.4,0.6,0.8,1))
library(Hmisc)
mergedData$gdp=cut2(mergedData$Gross.domestic.product.2012,g=5)
table(mergedData$Income.Group,mergedData$gdp)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = "q1.csv",
method = "curl")
q1 <- read.csv("q1.csv", header = TRUE)
# Question 1
# download file from server
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = "q1.csv",
method = "curl")
# read csv file
q1 <- read.csv("q1.csv", header = TRUE)
# load library
library(plyr)
library(dplyr)
# create a logical vector
q1 <- mutate(q1, agricultureLogical=factor((ACR == 3 & AGS == 6), levels = c(TRUE, FALSE)))
# show the first 3 row names which the logical value are TRUE
head(row.names(q1[which(q1$agricultureLogical == TRUE),]), 3)
library(plyr)
# Question 1
# download file from server
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = "q1.csv",
method = "curl")
# read csv file
q1 <- read.csv("q1.csv", header = TRUE)
# load library
library(plyr)
library(dplyr)
# create a logical vector
q1 <- mutate(q1, agricultureLogical=factor((ACR == 3 & AGS == 6), levels = c(TRUE, FALSE)))
# show the first 3 row names which the logical value are TRUE
head(row.names(q1[which(q1$agricultureLogical == TRUE),]), 3)
library(jpeg)
library(data.table)
library(dplyr)
library(jpeg)
library(data.table)
library(dplyr)
library(Hmisc)
install.packages(Hmisc)
library(swirl)
swirl()
install.packages(fields)
library(fields)
available.packages(contriburl = contrib.url(getOption("repos")),
method, fields = NULL)
download.packages(pkgs, destdir, available = NULL,
repos = getOption("repos"),
contriburl = contrib.url(repos, type),
method, type = getOption("pkgType"))
install.packages(pkgs, lib, repos = getOption("repos"),
contriburl = contrib.url(repos, type),
method, available = NULL, destdir = NULL,
installWithVers = FALSE, dependencies = NA,
type = getOption("pkgType"),
configure.args = character(0),
clean = FALSE)
install.packages(fields, repos="http://cran.r-project.org")
install.packages(fields, repos="https://cran.r-project.org/web/packages/fields/index.html")
install.packages('fields', repos="http://cran.r-project.org")
swirl()
omnitest(correctExpr='dim(pm0)')
dim(pm0)
dim(pm0)
head(pm0)
cnames
cnames <- strsplit(cnames, "|", fixed = TRUE)
cnames
names(pm0) <- make.names(cnames[[1]][wcol])
head(pm0)
x0 <- pm0$Sample.Value
str(x0)
mean(is.na(x0))
names(pm1) <- make.names(cnames[[1]][wcol])
dim(pm1)
x1 <- pm1$Sample.Value
mean(is.na(x1))
summary(x0)
summary(x1)
boxplot(x0, x1)
boxplot(log10(x0), log10(x1))
negative <- x1 < 0
sum(negative, na.rm = TRUE)
mean(negative, na.rm = TRUE)
dates <- pm1$Date
Type str(dates)
dates <- as.Date(as.character(dates), "%Y%m%d")
str(dates)
dates <- as.Date(as.character(dates), "%Y%m%d")
head(dates)
hist(dates[negative],"month")
str(site0)
both <- intersect(site0, site1)
both or print(both)
both
head(pm0)
cnt0 <- subset(pm0, State.Code == 36 & county.site %in% both)
cnt1 <- subset(pm1, State.Code == 36 & county.site %in% both)
sapply(split(cnt0, cnt0$county.site), nrow)
sapply(split(cnt1, cnt1$county.site), nrow)
pm0sub <- subset(cnt0, County.Code==63 & Site.ID==2008)
pm1sub <- subset(cnt1, County.Code==63 & Site.ID==2008)
x0sub <- pm0sub$Sample.Value
x1sub <- pm1sub$Sample.Value
dates0 <- as.Date(as.character(pm0sub$Date),"%Y%m%d")
dates1 <- as.Date(as.character(pm1sub$Date),"%Y%m%d")
par(mfrow = c(1, 2), mar = c(4, 4, 2, 1))
plot(dates0, x0sub, pch = 20)
abline(h = median(x0sub, na.rm = TRUE),lwd=2)
plot(dates1, x1sub, pch = 20)
abline(h = median(x1sub, na.rm = TRUE),lwd=2)
rng <- range(x0sub,x1sub,na.rm=TRUE)
rng or print(rng)
rng
mn0 <- with(pm0,tapply(Sample.Value,State.Code,mean,na.rm=TRUE))
str(mn0)
mn1 <- with(pm1,tapply(Sample.Value,State.Code,mean,na.rm=TRUE))
str(mn1)
summary(mn0)
summary(mn1)
d0 <- data.frame(state = names(mn0), mean = mn0)
d1 <- data.frame(state = names(mn1), mean = mn1)
mrg <- merge(d0, d1, by = "state")
dim(mrg)
head(mrg)
with(mrg, plot(rep(1, 52), mrg[, 2], xlim = c(.5, 2.5)))
with(mrg, points(rep(2, 52), mrg[, 3]))
segments(rep(1, 52), mrg[, 2], rep(2, 52), mrg[, 3])
mrg[mrg$mean.x < mrg$mean.y,]
library(swirl)
swirl()
swirl()
library(swirl)
0
0
swirl()
install_from_swirl("Reproducible Research")
install_from_swirl("Statistical Inference")
setwd("C:/Users/Jacob/Desktop/RepData_PeerAssessment1")
getwd()
?echo = TRUE
?echo
